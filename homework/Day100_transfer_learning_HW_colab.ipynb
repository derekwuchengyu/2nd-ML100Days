{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CbR0UP5JwLdT"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "# from resnet_builder import resnet # 這是從 resnet_builder.py 中直接 import 撰寫好的 resnet 函數\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ti9B-qKTwUoX"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "def resnet(input_shape, depth=29, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1105137,
     "status": "ok",
     "timestamp": 1570011594193,
     "user": {
      "displayName": "TW-吳乘宇",
      "photoUrl": "",
      "userId": "17158548348830124266"
     },
     "user_tz": -480
    },
    "id": "SsNp5XiAwYpf",
    "outputId": "44e6e846-2efb-4c40-a9fd-bd398e89ff2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 讀取資料集並作前處理\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1104560,
     "status": "ok",
     "timestamp": 1570011597390,
     "user": {
      "displayName": "TW-吳乘宇",
      "photoUrl": "",
      "userId": "17158548348830124266"
     },
     "user_tz": -480
    },
    "id": "Ffd4mqgbwZ7w",
    "outputId": "28f83025-7115-4fe7-e990-0ed9ec0fe981"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 16)   448         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 16)   64          conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 16)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 32, 32, 16)   272         activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 32, 32, 16)   64          conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 32, 32, 16)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 32, 32, 16)   2320        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 32, 32, 16)   64          conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 32, 32, 16)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 64)   1088        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 32, 32, 64)   1088        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 32, 32, 64)   0           conv2d_36[0][0]                  \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 32, 32, 64)   256         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 32, 32, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 16)   1040        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 32, 32, 16)   64          conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 32, 32, 16)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 16)   2320        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 32, 32, 16)   64          conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 32, 32, 16)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 64)   1088        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 32, 32, 64)   0           add_10[0][0]                     \n",
      "                                                                 conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 32, 32, 64)   256         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 32, 32, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 16)   1040        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 32, 16)   64          conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 32, 32, 16)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 32, 32, 16)   2320        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 16)   64          conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 16)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 64)   1088        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 32, 32, 64)   0           add_11[0][0]                     \n",
      "                                                                 conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 32, 64)   256         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 64)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 64)   4160        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 64)   256         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 64)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 64)   36928       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 64)   256         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 64)   0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 128)  8320        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 128)  8320        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 16, 16, 128)  0           conv2d_46[0][0]                  \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 128)  512         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 128)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 64)   8256        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 64)   256         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 64)   0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 64)   36928       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 64)   256         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 64)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 128)  8320        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 16, 16, 128)  0           add_13[0][0]                     \n",
      "                                                                 conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 128)  512         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 128)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 64)   8256        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 64)   256         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 64)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 64)   36928       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 64)   256         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 64)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 128)  8320        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 16, 16, 128)  0           add_14[0][0]                     \n",
      "                                                                 conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 128)  512         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 128)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 128)    16512       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 8, 128)    512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 128)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 128)    147584      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 8, 128)    512         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 128)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 256)    33024       add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 256)    33024       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 256)    0           conv2d_56[0][0]                  \n",
      "                                                                 conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 256)    1024        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 256)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 128)    32896       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 128)    512         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 128)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 128)    147584      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 128)    512         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 128)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 256)    33024       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 8, 256)    0           add_16[0][0]                     \n",
      "                                                                 conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 256)    1024        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 256)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 128)    32896       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 128)    512         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 128)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 128)    147584      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 128)    512         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 128)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 256)    33024       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 8, 8, 256)    0           add_17[0][0]                     \n",
      "                                                                 conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 256)    1024        add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 256)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 256)    0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 256)          0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           2570        flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 849,002\n",
      "Trainable params: 843,786\n",
      "Non-trainable params: 5,216\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = resnet(input_shape=(32,32,3)) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1109927,
     "status": "ok",
     "timestamp": 1570011593812,
     "user": {
      "displayName": "TW-吳乘宇",
      "photoUrl": "",
      "userId": "17158548348830124266"
     },
     "user_tz": -480
    },
    "id": "JxE-fEpX3QcP",
    "outputId": "a7768e6c-2533-4bdb-fcad-1022044f8d9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 41s 826us/step - loss: 0.3206 - acc: 0.9996 - val_loss: 1.3296 - val_acc: 0.7748\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 36s 730us/step - loss: 0.3195 - acc: 0.9997 - val_loss: 1.0414 - val_acc: 0.8243\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 37s 732us/step - loss: 0.3177 - acc: 0.9997 - val_loss: 1.2535 - val_acc: 0.7861\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 37s 734us/step - loss: 0.3163 - acc: 0.9997 - val_loss: 1.1034 - val_acc: 0.8170\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 37s 732us/step - loss: 0.3151 - acc: 0.9997 - val_loss: 1.0674 - val_acc: 0.8216\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 37s 733us/step - loss: 0.3145 - acc: 0.9994 - val_loss: 1.0571 - val_acc: 0.8205\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 37s 734us/step - loss: 0.3129 - acc: 0.9997 - val_loss: 1.0489 - val_acc: 0.8254\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 37s 731us/step - loss: 0.3115 - acc: 0.9997 - val_loss: 1.0590 - val_acc: 0.8251\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 37s 734us/step - loss: 0.3100 - acc: 0.9998 - val_loss: 1.0591 - val_acc: 0.8240\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 37s 733us/step - loss: 0.3091 - acc: 0.9998 - val_loss: 1.0909 - val_acc: 0.8177\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 37s 733us/step - loss: 0.3079 - acc: 0.9998 - val_loss: 1.1161 - val_acc: 0.8101\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 37s 732us/step - loss: 0.3066 - acc: 0.9999 - val_loss: 1.0614 - val_acc: 0.8229\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 37s 734us/step - loss: 0.3058 - acc: 0.9998 - val_loss: 1.0870 - val_acc: 0.8218\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 37s 734us/step - loss: 0.3045 - acc: 0.9998 - val_loss: 1.0806 - val_acc: 0.8207\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 37s 734us/step - loss: 0.3035 - acc: 0.9998 - val_loss: 1.0637 - val_acc: 0.8231\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 37s 736us/step - loss: 0.3024 - acc: 0.9998 - val_loss: 1.2355 - val_acc: 0.8009\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 37s 732us/step - loss: 0.3013 - acc: 0.9999 - val_loss: 1.0712 - val_acc: 0.8219\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 37s 732us/step - loss: 0.3001 - acc: 0.9999 - val_loss: 1.0921 - val_acc: 0.8169\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 37s 732us/step - loss: 0.2991 - acc: 1.0000 - val_loss: 1.0712 - val_acc: 0.8237\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 37s 732us/step - loss: 0.2981 - acc: 0.9998 - val_loss: 1.0736 - val_acc: 0.8238\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 37s 733us/step - loss: 0.2972 - acc: 0.9999 - val_loss: 1.0839 - val_acc: 0.8228\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 37s 734us/step - loss: 0.2961 - acc: 1.0000 - val_loss: 1.0943 - val_acc: 0.8218\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 37s 730us/step - loss: 0.2949 - acc: 0.9998 - val_loss: 1.0800 - val_acc: 0.8233\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 37s 733us/step - loss: 0.2940 - acc: 0.9999 - val_loss: 1.0819 - val_acc: 0.8224\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 37s 731us/step - loss: 0.2929 - acc: 0.9999 - val_loss: 1.0761 - val_acc: 0.8236\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 37s 731us/step - loss: 0.2918 - acc: 0.9999 - val_loss: 1.0872 - val_acc: 0.8227\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 37s 731us/step - loss: 0.2912 - acc: 0.9998 - val_loss: 1.0815 - val_acc: 0.8231\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 37s 732us/step - loss: 0.2901 - acc: 1.0000 - val_loss: 1.0825 - val_acc: 0.8231\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 37s 732us/step - loss: 0.2891 - acc: 0.9999 - val_loss: 1.0842 - val_acc: 0.8243\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 37s 732us/step - loss: 0.2882 - acc: 0.9999 - val_loss: 1.0860 - val_acc: 0.8223\n",
      "Test loss: 1.086039862060547\n",
      "Test accuracy: 0.8223\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 30 # 訓練整個資料集共 30個循環\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='SGD',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1240816,
     "status": "ok",
     "timestamp": 1570009541154,
     "user": {
      "displayName": "TW-吳乘宇",
      "photoUrl": "",
      "userId": "17158548348830124266"
     },
     "user_tz": -480
    },
    "id": "2MKeshtBwcp3",
    "outputId": "71b457c7-15a3-49fd-819e-097f621f9777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 50s 997us/step - loss: 1.8154 - acc: 0.5173 - val_loss: 1.6225 - val_acc: 0.5508\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 40s 805us/step - loss: 1.3198 - acc: 0.6609 - val_loss: 1.6851 - val_acc: 0.5544\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 40s 800us/step - loss: 1.1215 - acc: 0.7212 - val_loss: 1.4251 - val_acc: 0.6163\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 40s 801us/step - loss: 0.9898 - acc: 0.7642 - val_loss: 1.2495 - val_acc: 0.6882\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 40s 801us/step - loss: 0.8917 - acc: 0.7952 - val_loss: 1.1856 - val_acc: 0.6899\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 40s 805us/step - loss: 0.8193 - acc: 0.8202 - val_loss: 1.3523 - val_acc: 0.6939\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 40s 801us/step - loss: 0.7609 - acc: 0.8384 - val_loss: 1.0431 - val_acc: 0.7479\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 40s 804us/step - loss: 0.7185 - acc: 0.8526 - val_loss: 1.3383 - val_acc: 0.6905\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 40s 800us/step - loss: 0.6777 - acc: 0.8678 - val_loss: 1.0961 - val_acc: 0.7288\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 40s 799us/step - loss: 0.6469 - acc: 0.8792 - val_loss: 1.1495 - val_acc: 0.7382\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 40s 800us/step - loss: 0.6142 - acc: 0.8921 - val_loss: 1.5100 - val_acc: 0.6663\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 40s 800us/step - loss: 0.5978 - acc: 0.8995 - val_loss: 1.1446 - val_acc: 0.7456\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 40s 798us/step - loss: 0.5777 - acc: 0.9067 - val_loss: 1.3363 - val_acc: 0.7383\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 40s 802us/step - loss: 0.5665 - acc: 0.9117 - val_loss: 1.1522 - val_acc: 0.7665\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 40s 798us/step - loss: 0.5487 - acc: 0.9192 - val_loss: 1.1986 - val_acc: 0.7579\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 40s 801us/step - loss: 0.5375 - acc: 0.9230 - val_loss: 1.2261 - val_acc: 0.7533\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 40s 799us/step - loss: 0.5287 - acc: 0.9256 - val_loss: 1.3919 - val_acc: 0.7235\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 40s 802us/step - loss: 0.5218 - acc: 0.9294 - val_loss: 1.3280 - val_acc: 0.7531\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 40s 799us/step - loss: 0.5202 - acc: 0.9298 - val_loss: 1.4467 - val_acc: 0.7175\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 40s 797us/step - loss: 0.5090 - acc: 0.9335 - val_loss: 1.1242 - val_acc: 0.7801\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 40s 801us/step - loss: 0.5095 - acc: 0.9346 - val_loss: 1.4229 - val_acc: 0.7163\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 40s 803us/step - loss: 0.4973 - acc: 0.9393 - val_loss: 1.6555 - val_acc: 0.6877\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 40s 796us/step - loss: 0.4982 - acc: 0.9394 - val_loss: 1.7639 - val_acc: 0.7009\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 40s 793us/step - loss: 0.4964 - acc: 0.9393 - val_loss: 1.5178 - val_acc: 0.7268\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 40s 794us/step - loss: 0.4901 - acc: 0.9431 - val_loss: 1.7347 - val_acc: 0.6847\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 40s 796us/step - loss: 0.4812 - acc: 0.9458 - val_loss: 1.3386 - val_acc: 0.7287\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 40s 793us/step - loss: 0.4878 - acc: 0.9426 - val_loss: 1.6860 - val_acc: 0.7068\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 40s 795us/step - loss: 0.4849 - acc: 0.9442 - val_loss: 1.8134 - val_acc: 0.7038\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 40s 796us/step - loss: 0.4745 - acc: 0.9481 - val_loss: 1.2810 - val_acc: 0.7483\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 40s 797us/step - loss: 0.4760 - acc: 0.9467 - val_loss: 1.6680 - val_acc: 0.7179\n",
      "Test loss: 1.6680099618911743\n",
      "Test accuracy: 0.7179\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # batch 的大小，如果出現 OOM error，請降低這個值\n",
    "num_classes = 10 # 類別的數量，Cifar 10 共有 10 個類別\n",
    "epochs = 30 # 訓練整個資料集共 30個循環\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9WvGfKbyXrf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Day100.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
